---
title: "Topic Modelling"
date: today
format:
  html: default
  pdf: default
  docx: default
editor: visual
execute: 
  echo: true
  warning: false
  message: false
---

## Methods

We conducted topic modelling on bibliographic data exported from Rayyan.

RIS files were imported with the `synthesisr` package, cleaned, and converted into a document-feature matrix using **quanteda**.

We applied both unsupervised Latent Dirichlet Allocation (LDA) and semi-supervised seededLDA, using a domain-specific dictionary to improve interpretability.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: load data and libraries
library(tidyverse)
library(seededlda)
library(synthesisr)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(LDAvis)
library(pheatmap)
library(kableExtra)
library(DBI)

con <- dbConnect(RSQLite::SQLite(), 
   "screening/INCLUDES fixed abstracts.Data/sdb/sdb.eni"
)

# The core table containing title + abstract is "refs"
refs <- dbReadTable(con, "refs")
dbDisconnect(con)

# Inspect available fields:
# names(refs)

title_col <- if ("title" %in% names(refs)) "title" else names(refs)[str_detect(names(refs),"title")]
abstract_col <- if ("abstract" %in% names(refs)) "abstract" else names(refs)[str_detect(names(refs),"ab")][1]

# Build text corpus
corp <- paste(refs[[title_col]], refs[[abstract_col]])

# Optional cleanup: remove “References …” text if present
corp <- sub("References.*$", "", corp)

# ---- Tokenise ----
toks <- tokens(
  corp,
  remove_punct = TRUE,
  remove_symbols = TRUE,
  remove_numbers = TRUE,
  remove_url = TRUE
)
# ---- Stopwords (with 3-character removal rule) ----

extra_stopwords <- c(
  "jats","italic","italics","abstract","copyright",
  "et al.","et al",
  "research","article","results","methodology","introduction",
  "background","discussion","paper","science","report","author","issue",
  "references","full-text","version","papers","bold","style","list",
  "published","h1","h2","h3"
)

stopword_list <- c(stopwords("en"), extra_stopwords)


# remove stopwords
toks <- tokens_remove(toks, stopword_list)

# remove 1–3 character tokens BEFORE dfm
toks <- tokens_remove(toks, "^\\w{1,3}$")


# ---- Remove: 
#   - standard stopwords
#   - 1–2 character words
#   - 3-character words
# ----

dfmt <- dfm(toks) |>
  dfm_remove(stopword_list) |>
  dfm_remove("^\\w{1,3}$") |>        # removes tokens of length 1–3
  dfm_trim(max_docfreq = 0.1, docfreq_type = "prop")

```

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: lda modelling
# standard LDA
lda <- textmodel_lda(dfmt, k = 20, verbose = FALSE)

# seeded LDA
dict <- dictionary(file = "dictionary.yml")

lda_seed <- textmodel_seededlda(
  dfmt,
  dict,
  batch_size = 0.01,
  auto_iter = TRUE,
  verbose = FALSE
)


```

## Results

### Topic Prevalence

We calculated the mean prevalence of each topic across the corpus.Topic prevalence indicates the proportion of content associated with each topic across the corpus, highlighting which themes are dominant versus niche.In a seededLDA the prevalence may be skewed toward the dictionary of terms inflating the prevalence of rare terms.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: Topic prevalence
# 1) Prevalence per topic
topic_props <- colMeans(lda_seed$theta)
topic_props_df <- tibble(topic = seq_along(topic_props),
                         Prevalence = round(topic_props, 3))

# 2) Top terms per topic (robust to list/matrix return types)
seed_top <- terms(lda_seed, 10)

if (is.list(seed_top)) {
  seed_terms_tbl <- tibble(
    topic = seq_along(seed_top),
    Topic_Label = if (!is.null(names(seed_top))) names(seed_top) else paste0("Topic ", seq_along(seed_top)),
    Top_Terms = vapply(seed_top, function(x) paste(x, collapse = ", "), character(1))
  )
} else {
  # assume matrix with topics in columns
  seed_terms_tbl <- tibble(
    topic = seq_len(ncol(seed_top)),
    Topic_Label = if (!is.null(colnames(seed_top))) colnames(seed_top) else paste0("Topic ", seq_len(ncol(seed_top))),
    Top_Terms = apply(seed_top, 2, function(x) paste(x, collapse = ", "))
  )
}

# 3) Join prevalence (guarantees correct alignment)
topic_summary <- seed_terms_tbl  |> 
  left_join(topic_props_df, by = "topic") %>%
  arrange(desc(Prevalence))

kable(topic_summary, caption = "Seeded LDA: Top terms and topic prevalence")

```

### Top Terms per Topic (same as table--- could be prettier)

The most frequent terms characterising each topic are shown below.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: top terms barplot
ggplot(topic_summary, aes(x = reorder(factor(topic), Prevalence), y = Prevalence)) +
  geom_col(fill = "darkgreen") +
  geom_text(aes(label = Top_Terms), hjust = 0, size = 2.5) +
  coord_flip() +
  labs(
    x = "Topic",
    y = "Prevalence",
    title = "Topic Prevalence with Top Terms"
  ) +
  theme_minimal()

```

### Heatmap of Documents × Topics

This shows the distribution of topics across the first 50 documents (rows clustered).

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: heatmap

pheatmap(lda_seed$theta[1:50, ], 
         cluster_rows = TRUE, cluster_cols = TRUE,
         main = "Topic distribution across documents")
```

The topics with the largest number of documents are highlighted in warmer colours (farm management and legislation).

### Interactive Exploration (Supplementary??)

We also generated an interactive LDAvis visualisation (HTML only, not for PDF).

```{r}
#| echo: false
#| warning: false
#| message: false
#| eval: false
json <- createJSON(phi = lda_seed$phi, 
                   theta = lda_seed$theta, 
                   doc.length = rowSums(dfmt), 
                   vocab = colnames(dfmt), 
                   term.frequency = colSums(dfmt))

serVis(json)
```

## Interpretation

Seeded LDA produced topics consistent with the predefined dictionary, ensuring interpretability.Topic prevalence highlights dominant themes in the literature.

## Compare seeded and unseeded LDA

### Compare top terms per topic

```{r}
top_terms_unseeded <- terms(lda, 10)
top_terms_seeded <- terms(lda_seed, 10)

# Combine into comparison table
compare_terms <- data.frame(
  Topic = rep(1:10, 2),
  Model = rep(c("Unseeded", "Seeded"), each = 10),
  Terms = c(sapply(top_terms_unseeded[1:10], paste, collapse = ", "),
            sapply(top_terms_seeded[1:10], paste, collapse = ", "))
)

knitr::kable(compare_terms, row.names = FALSE, caption = "Comparison of top terms by model")


```

This shows that the seeded LDA pulls topics closer to our dictionary.

### Compare document assignment stability

For each document, compare the “most likely topic” under seeded vs unseeded.

```{r}
doc_topics_unseeded <- apply(lda$theta, 1, which.max)
doc_topics_seeded <- apply(lda_seed$theta, 1, which.max)

agreement <- mean(doc_topics_unseeded == doc_topics_seeded)
agreement


```

We compared document-level topic assignments between unseeded LDA and seeded LDA. Only `r round(agreement*100,2)` % of documents were assigned to the same dominant topic under both models, indicating that the seeded model substantially reallocated documents to dictionary-guided topics.

## Co-author network


```{r}
library(igraph)

# (1) Explode authors
authors_df <- refs %>%
  filter(!is.na(author)) %>%
  mutate(authors = str_split(author, ";|,| and ", simplify = FALSE)) %>%
  mutate(authors = map(authors, ~str_trim(.x))) %>%
  mutate(authors = map(authors, ~.x[.x != ""])) %>%
  filter(lengths(authors) > 0)

# (2) Keep only papers with *multiple* authors
multi_author <- authors_df %>%
  filter(lengths(authors) >= 2)

# (3) Build pairwise edges safely
edges <- multi_author %>%
  transmute(
    id = id,
    pairs = map(authors, ~combn(.x, 2, simplify = FALSE))
  ) %>%
  unnest(pairs) %>%
  mutate(
    source = map_chr(pairs, 1),
    target = map_chr(pairs, 2)
  ) %>%
  select(source, target)

# (4) Build graph
g_auth <- graph_from_data_frame(edges, directed = FALSE)

plot(g_auth,
     vertex.size = 5,
     vertex.label = NA,
     layout = layout_with_fr,
     edge.color = "grey70")


```







## Citation analysis

```{r}
dois <- refs %>%
  mutate(doi = electronic_resource_number) %>%
  filter(!is.na(doi), doi != "") %>%
  distinct(doi)

```


```{r}
library(openalexR)
library(purrr)
library(dplyr)

# list of DOIs
doi_vec <- dois$doi

fetch_one <- function(doi) {
  oa_fetch(
    identifier = paste0("doi:", doi),
    entity = "works"
  )
}

# safe version: returns NULL on errors
fetch_one_safe <- safely(fetch_one, otherwise = NULL)

works_list <- map(doi_vec, fetch_one_safe)

# extract results
works <- bind_rows(
  map(works_list, "result")   # extract $result inside `safely()` output
)

```

```{r}

edges <- works %>%
  select(id, referenced_works) %>%
  unnest(referenced_works) %>%
  rename(source = id, target = referenced_works)

```


```{r}
g_citation <- graph_from_data_frame(edges, directed = TRUE)
plot(g_citation,
     vertex.size = 3,
     vertex.label = NA,
     edge.arrow.size = 0.2,
     layout = layout_with_fr)

```


```{r}
g_und <- as_undirected(g_citation)

clusters <- cluster_louvain(g_und)
V(g_citation)$cluster <- clusters$membership
plot(g_citation,
     vertex.size = 4,
     vertex.label = NA,
     vertex.color = V(g_citation)$cluster,
     layout = layout_with_fr)

```

